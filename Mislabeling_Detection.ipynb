{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-omics Enabled Sample Mislabeling Correction Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is using various classifiers in an attempt to detect sample misclassifications\n",
    "\n",
    "Details about this challenge: https://precision.fda.gov/challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import getopt\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, cross_validate, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"challenge_data/train_cli.tsv\", sep=\"\\t\", index_col=\"sample\")\n",
    "proteins = pd.read_csv(\"challenge_data/train_pro.tsv\", sep=\"\\t\")\n",
    "# Transpose proteins matrix\n",
    "proteins = proteins.T\n",
    "misClassified = pd.read_csv(\"challenge_data/sum_tab_1.csv\", sep=\",\")\n",
    "# Replace missing values with median\n",
    "proteins = proteins.fillna(proteins.median())\n",
    "# Drop remaining columns with missing values\n",
    "proteins = proteins.dropna(axis='columns')\n",
    "\n",
    "# What if missing values are not really missing values but missing genes (Y chrom for instance)\n",
    "# proteins = proteins.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select only rows which were correctly classified (matches) for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = list(misClassified.query('mismatch==0').loc[:,\"sample\"])\n",
    "x = proteins.loc[matches]\n",
    "y = labels.loc[matches]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Classifications\n",
    "First exploration of how different classifiers perform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for combining the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineLabels(a, b):\n",
    "    combined =  [None] * len(a)\n",
    "    for i in range(len(a)):\n",
    "        if (a[i] == 0 and b[i] == 0):\n",
    "            combined[i] = 0\n",
    "        if (a[i] == 0 and b[i] == 1):\n",
    "            combined[i] = 1\n",
    "        if (a[i] == 1 and b[i] == 0):\n",
    "            combined[i] = 2\n",
    "        if (a[i] == 1 and b[i] == 1):\n",
    "            combined[i] = 3\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test a classifier on msi, gender and combined labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(x, y, clf):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, shuffle=True)\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    # I will have separat models for gende and msi\n",
    "    y_gender_train = lb.fit_transform(y_train.loc[:,\"gender\"]).ravel()\n",
    "    y_gender_test = lb.fit_transform(y_test.loc[:,\"gender\"]).ravel()\n",
    "    y_msi_train = lb.fit_transform(y_train.loc[:,\"msi\"]).ravel()\n",
    "    y_msi_test = lb.fit_transform(y_test.loc[:,\"msi\"]).ravel()\n",
    "\n",
    "    y_combined_train = combineLabels(y_gender_train, y_msi_train)\n",
    "    y_combined_test = combineLabels(y_gender_test, y_msi_test)\n",
    "\n",
    "    clf.fit(x_train, y_gender_train)\n",
    "\n",
    "    y_gender_predict = clf.predict(x_train)\n",
    "    print(\"Gender train accuracy:\", accuracy_score(y_gender_train, y_gender_predict))\n",
    "\n",
    "    y_gender_predict = clf.predict(x_test)\n",
    "    print(\"Gender test accuracy:\", accuracy_score(y_gender_test, y_gender_predict))\n",
    "\n",
    "    clf.fit(x_train, y_msi_train)\n",
    "\n",
    "    y_msi_predict = clf.predict(x_train)\n",
    "    print(\"Msi train accuracy:\", accuracy_score(y_msi_train, y_msi_predict))\n",
    "\n",
    "    y_msi_predict = clf.predict(x_test)\n",
    "    print(\"Msi test accuracy:\", accuracy_score(y_msi_test, y_msi_predict))\n",
    "    \n",
    "    clf.fit(x_train, y_combined_train)\n",
    "    \n",
    "    y_combined_predict = clf.predict(x_train)\n",
    "    print(\"Combined train accuracy:\", accuracy_score(y_combined_train, y_combined_predict))\n",
    "    # print(\"Msi train F1:\", f1_score(y_msi_train, y_msi_predict))\n",
    "\n",
    "    y_combined_predict = clf.predict(x_test)\n",
    "    print(\"Combined test accuracy:\", accuracy_score(y_combined_test, y_combined_predict))\n",
    "    # print(\"Msi train F1:\", f1_score(y_msi_test, y_msi_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM\n",
    "\n",
    "* It seems that a high penalty needs to be set for SVM, otherwise it assigns the more frequent label (female and low msi) to everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Gender train accuracy:', 1.0)\n",
      "('Gender test accuracy:', 0.7142857142857143)\n",
      "('Msi train accuracy:', 1.0)\n",
      "('Msi test accuracy:', 0.8571428571428571)\n",
      "('Combined train accuracy:', 1.0)\n",
      "('Combined test accuracy:', 0.5714285714285714)\n"
     ]
    }
   ],
   "source": [
    "classify(x, y, SVC(C=100, kernel=\"rbf\", gamma=\"scale\", probability=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Gender train accuracy:', 0.9787234042553191)\n",
      "('Gender test accuracy:', 0.6190476190476191)\n",
      "('Msi train accuracy:', 1.0)\n",
      "('Msi test accuracy:', 0.8095238095238095)\n",
      "('Combined train accuracy:', 1.0)\n",
      "('Combined test accuracy:', 0.42857142857142855)\n"
     ]
    }
   ],
   "source": [
    "classify(x, y, RandomForestClassifier(n_estimators = 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Gender train accuracy:', 0.7872340425531915)\n",
      "('Gender test accuracy:', 0.7142857142857143)\n",
      "('Msi train accuracy:', 0.9361702127659575)\n",
      "('Msi test accuracy:', 0.8095238095238095)\n",
      "('Combined train accuracy:', 0.7659574468085106)\n",
      "('Combined test accuracy:', 0.5238095238095238)\n"
     ]
    }
   ],
   "source": [
    "classify(x, y, KNeighborsClassifier(n_neighbors=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it's time to figure out the best parameters for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender = y.loc[:,\"gender\"]\n",
    "msi = y.loc[:,\"msi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestParams(x, y, clf, grid):\n",
    "    grid_search = GridSearchCV(clf, param_grid=grid, cv=10, iid=False)\n",
    "    grid_search.fit(x, y)\n",
    "    print(\"Tuned params:\", grid_search.best_params_)\n",
    "    print(\"Tuned best acc:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for gender\n",
      "('Tuned params:', {'n_estimators': 25, 'max_depth': 74})\n",
      "('Tuned best acc:', 0.7410714285714286)\n",
      "Best params for msi\n",
      "('Tuned params:', {'n_estimators': 5, 'max_depth': 59})\n",
      "('Tuned best acc:', 0.8875000000000002)\n"
     ]
    }
   ],
   "source": [
    "grid = {\n",
    "    \"n_estimators\": range(5, 35, 5),\n",
    "    \"max_depth\": range(4, 120, 5)\n",
    "}\n",
    "print(\"Best params for gender\")\n",
    "bestParams(x, gender, RandomForestClassifier(), grid)\n",
    "print(\"Best params for msi\")\n",
    "bestParams(x, msi, RandomForestClassifier(), grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for gender\n",
      "('Tuned params:', {'kernel': 'rbf', 'C': 10, 'gamma': 'auto'})\n",
      "('Tuned best acc:', 0.6708333333333334)\n",
      "Best params for msi\n",
      "('Tuned params:', {'kernel': 'linear', 'C': 0.01, 'gamma': 'auto'})\n",
      "('Tuned best acc:', 0.9)\n"
     ]
    }
   ],
   "source": [
    "grid = {\n",
    "    \"C\": [pow(10,i) for i in range(-2,4)],\n",
    "    \"kernel\": [\"linear\", \"rbf\"],\n",
    "    \"gamma\": [\"auto\", \"scale\"]\n",
    "}\n",
    "print(\"Best params for gender\")\n",
    "bestParams(x, gender, SVC(), grid)\n",
    "print(\"Best params for msi\")\n",
    "bestParams(x, msi, SVC(), grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for gender\n",
      "('Tuned params:', {'n_neighbors': 5})\n",
      "('Tuned best acc:', 0.7345238095238096)\n",
      "Best params for msi\n",
      "('Tuned params:', {'n_neighbors': 9})\n",
      "('Tuned best acc:', 0.9041666666666668)\n"
     ]
    }
   ],
   "source": [
    "grid = {\n",
    "    \"n_neighbors\": range(1,20)\n",
    "}\n",
    "print(\"Best params for gender\")\n",
    "bestParams(x, gender, KNeighborsClassifier(), grid)\n",
    "print(\"Best params for msi\")\n",
    "bestParams(x, msi, KNeighborsClassifier(), grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for gender\n",
      "('Tuned params:', {'solver': 'lbfgs'})\n",
      "('Tuned best acc:', 0.6708333333333333)\n",
      "Best params for msi\n",
      "('Tuned params:', {'solver': 'lbfgs'})\n",
      "('Tuned best acc:', 0.8875)\n"
     ]
    }
   ],
   "source": [
    "grid = {\n",
    "    \"solver\": [\"lbfgs\", \"liblinear\"]\n",
    "}\n",
    "print(\"Best params for gender\")\n",
    "bestParams(x, gender, LogisticRegression(), grid)\n",
    "print(\"Best params for msi\")\n",
    "bestParams(x, msi, LogisticRegression(), grid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADA Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for gender\n",
      "('Tuned params:', {'n_estimators': 45})\n",
      "('Tuned best acc:', 0.7761904761904762)\n",
      "Best params for msi\n",
      "('Tuned params:', {'n_estimators': 45})\n",
      "('Tuned best acc:', 0.8416666666666668)\n"
     ]
    }
   ],
   "source": [
    "grid = {\n",
    "    \"n_estimators\": range(40, 60, 5)\n",
    "}\n",
    "print(\"Best params for gender\")\n",
    "bestParams(x, gender, AdaBoostClassifier(), grid)\n",
    "print(\"Best params for msi\")\n",
    "bestParams(x, msi, AdaBoostClassifier(), grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Combine MSI and Gender?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Msi seems to be better indicator than gender. How do we take this into account?\n",
    "\n",
    "* MSI does not match --> Mismatch label, no matter what gender says\n",
    "* MSI matching, gender mismatch - what do we do?\n",
    "* I propose to calculate a confidence score and use it in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Confidence Score\n",
    "* Instead of reporting just label, show model's confidence score. This can help us decide in case of matching msi and gender misclassification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Gender test accuracy:', 0.6190476190476191)\n",
      "(array([0.68232265, 0.31767735]), 1)\n",
      "(array([0.69272413, 0.30727587]), 0)\n",
      "(array([0.68428927, 0.31571073]), 1)\n",
      "(array([0.68667506, 0.31332494]), 0)\n",
      "(array([0.6249667, 0.3750333]), 1)\n",
      "(array([0.45015556, 0.54984444]), 1)\n",
      "(array([0.82886351, 0.17113649]), 1)\n",
      "(array([0.66656119, 0.33343881]), 0)\n",
      "(array([0.66511439, 0.33488561]), 1)\n",
      "(array([0.74174193, 0.25825807]), 0)\n",
      "(array([0.78911414, 0.21088586]), 1)\n",
      "(array([0.68384196, 0.31615804]), 0)\n",
      "(array([0.81968649, 0.18031351]), 0)\n",
      "(array([0.65743684, 0.34256316]), 0)\n",
      "(array([0.74588987, 0.25411013]), 0)\n",
      "(array([0.64746958, 0.35253042]), 0)\n",
      "(array([0.86540917, 0.13459083]), 1)\n",
      "(array([0.66728588, 0.33271412]), 1)\n",
      "(array([0.76230683, 0.23769317]), 0)\n",
      "(array([0.55475304, 0.44524696]), 1)\n",
      "(array([0.75708745, 0.24291255]), 0)\n",
      "()\n",
      "('Msi test accuracy:', 1.0)\n",
      "(array([0.15381273, 0.84618727]), 1)\n",
      "(array([0.03480029, 0.96519971]), 1)\n",
      "(array([0.1559887, 0.8440113]), 1)\n",
      "(array([0.08524463, 0.91475537]), 1)\n",
      "(array([0.66457062, 0.33542938]), 0)\n",
      "(array([0.08838087, 0.91161913]), 1)\n",
      "(array([0.02381407, 0.97618593]), 1)\n",
      "(array([0.07354278, 0.92645722]), 1)\n",
      "(array([0.08643869, 0.91356131]), 1)\n",
      "(array([0.84184809, 0.15815191]), 0)\n",
      "(array([0.1406746, 0.8593254]), 1)\n",
      "(array([0.24675432, 0.75324568]), 1)\n",
      "(array([0.15267025, 0.84732975]), 1)\n",
      "(array([0.03410449, 0.96589551]), 1)\n",
      "(array([0.11117382, 0.88882618]), 1)\n",
      "(array([0.52740288, 0.47259712]), 0)\n",
      "(array([0.14477598, 0.85522402]), 1)\n",
      "(array([0.85975401, 0.14024599]), 0)\n",
      "(array([0.08284083, 0.91715917]), 1)\n",
      "(array([0.13645816, 0.86354184]), 1)\n",
      "(array([0.09175199, 0.90824801]), 1)\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(C=100, kernel=\"rbf\", gamma=\"scale\", probability=True)\n",
    "#clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, shuffle=True, random_state=100)\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "y_gender_train = lb.fit_transform(y_train.loc[:,\"gender\"]).ravel()\n",
    "y_gender_test = lb.fit_transform(y_test.loc[:,\"gender\"]).ravel()\n",
    "y_msi_train = lb.fit_transform(y_train.loc[:,\"msi\"]).ravel()\n",
    "y_msi_test = lb.fit_transform(y_test.loc[:,\"msi\"]).ravel()\n",
    "\n",
    "clf.fit(x_train, y_gender_train)\n",
    "y_gender_predict = clf.predict(x_test)\n",
    "print(\"Gender test accuracy:\", accuracy_score(y_gender_test, y_gender_predict))\n",
    "probs = clf.predict_proba(x_test)\n",
    "for i in range(len(probs)):\n",
    "    print(probs[i] , y_gender_test[i])\n",
    "print()\n",
    "\n",
    "clf.fit(x_train, y_msi_train)\n",
    "y_msi_predict = clf.predict(x_test)\n",
    "print(\"Msi test accuracy:\", accuracy_score(y_msi_test, y_msi_predict))\n",
    "probs = clf.predict_proba(x_test)\n",
    "for i in range(len(probs)):\n",
    "    print(probs[i], y_msi_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, it does not look like the confidence is helpful when predicting gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train all classifiers with best parameters (discovered by grid search) and run them on the test set.\n",
    "Each time, use a different subset (80%) to give each model slightly different data to reduce overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalPredict(x_train, y_train, x_test, y_test, clf):\n",
    "    x_train_subset, a, y_train_subset, b = train_test_split(x_train, y_train, test_size=0.2, shuffle=True)\n",
    "    clf.fit(x_train_subset, y_train_subset)\n",
    "    y_predict = clf.predict(x_test)\n",
    "    print(\"Test accuracy:\", accuracy_score(y_test, y_predict))\n",
    "    return y_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict with all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test accuracy:', 0.45)\n",
      "('Test accuracy:', 0.8125)\n",
      "('Test accuracy:', 0.3375)\n",
      "('Test accuracy:', 0.85)\n",
      "('Test accuracy:', 0.375)\n",
      "('Test accuracy:', 0.8625)\n",
      "('Test accuracy:', 0.5)\n",
      "('Test accuracy:', 0.7375)\n"
     ]
    }
   ],
   "source": [
    "# Load test data in the same way train data was loaded\n",
    "labels_test = pd.read_csv(\"challenge_data/test_cli.tsv\", sep=\"\\t\", index_col=\"sample\")\n",
    "proteins_test = pd.read_csv(\"challenge_data/test_pro.tsv\", sep=\"\\t\")\n",
    "proteins_test = proteins_test.T\n",
    "proteins_test = proteins_test.fillna(proteins.median())\n",
    "proteins_test = proteins_test.dropna(axis='columns')\n",
    "\n",
    "gender_test = labels_test.loc[:,\"gender\"]\n",
    "msi_test = labels_test.loc[:,\"msi\"]\n",
    "\n",
    "predictions =  [None] * 8\n",
    "\n",
    "predictions[0] = finalPredict(x, gender, proteins_test, gender_test, RandomForestClassifier(n_estimators = 10, max_depth = 104))\n",
    "predictions[4] = finalPredict(x, msi, proteins_test, msi_test, RandomForestClassifier(n_estimators = 10, max_depth = 39))\n",
    "\n",
    "predictions[1] = finalPredict(x, gender, proteins_test, gender_test, SVC(C=100, kernel=\"rbf\", gamma=\"auto\"))\n",
    "predictions[5] = finalPredict(x, msi, proteins_test, msi_test, SVC(C=0.01, kernel=\"linear\", gamma=\"auto\"))\n",
    "\n",
    "predictions[2] = finalPredict(x, gender, proteins_test, gender_test, KNeighborsClassifier(n_neighbors=7))\n",
    "predictions[6] = finalPredict(x, msi, proteins_test, msi_test, KNeighborsClassifier(n_neighbors=9))\n",
    "\n",
    "# Results of logistic regression are too similar to SVM, there is no point in using it\n",
    "#predictions[3] = finalPredict(x, gender, proteins_test, gender_test, LogisticRegression(solver=\"lbfgs\"))\n",
    "#predictions[7] = finalPredict(x, msi, proteins_test, msi_test, LogisticRegression(solver=\"lbfgs\"))\n",
    "\n",
    "predictions[3] = finalPredict(x, gender, proteins_test, gender_test, AdaBoostClassifier(n_estimators = 45))\n",
    "predictions[7] = finalPredict(x, msi, proteins_test, msi_test, AdaBoostClassifier(n_estimators = 45))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the predictions of all models agree and they are different from annotation, set the mislabeled flag to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "extensiveOut = open(\"extensive.csv\",\"w+\")\n",
    "finalOut = open(\"submission.csv\",\"w+\")\n",
    "names = list(labels_test.index)\n",
    "\n",
    "extensiveOut.write(\"sample,Test_gender,Test_msi, RandomForest_gender,SVM_gender,KNN_gender,ADA_gender,RandomForest_msi,SVM_msi,KNN_msi,ADA_msi,gender_mislabeled,msi_mislabeld,mislabeled\\n\")\n",
    "finalOut.write(\"sample,mismatch\\n\")\n",
    "for i in range(len(predictions[0])):\n",
    "    gender_mislabeled = \"0\"\n",
    "    msi_mislabeled = \"0\"\n",
    "    mislabeled = \"0\"\n",
    "    if (predictions[0][i] == predictions[1][i] and predictions[0][i] == predictions[2][i] \n",
    "        and predictions[0][i] == predictions[3][i] and predictions[0][i] != labels_test.iloc[i,0]):\n",
    "        gender_mislabeled = \"1\"\n",
    "        \n",
    "    if (predictions[4][i] == predictions[5][i] and predictions[4][i] == predictions[6][i] \n",
    "        and predictions[4][i] == predictions[7][i] and predictions[4][i] != labels_test.iloc[i,1]):\n",
    "        msi_mislabeled = \"1\"\n",
    "        \n",
    "    if (msi_mislabeled == \"1\" or gender_mislabeled == \"1\"):\n",
    "        mislabeled = \"1\"\n",
    "\n",
    "    extensiveOut.write(names[i] + \",\" + labels_test.iloc[i,0] + \",\" + labels_test.iloc[i,1])\n",
    "    for j in range(len(predictions)):\n",
    "        extensiveOut.write(\",\" + predictions[j][i])\n",
    "    extensiveOut.write(\", \" + gender_mislabeled + \",\" + msi_mislabeled + \",\" + mislabeled)\n",
    "    extensiveOut.write(\"\\n\")\n",
    "    \n",
    "    finalOut.write(names[i] + \",\" + mislabeled + \"\\n\")\n",
    "\n",
    "extensiveOut.close()\n",
    "finalOut.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
