{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-omics Enabled Sample Mislabeling Correction Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is using various classifiers in an attempt to detect sample misclassifications\n",
    "\n",
    "Details about this challenge: https://precision.fda.gov/challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import getopt\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, cross_validate, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"challenge_data/train_cli.tsv\", sep=\"\\t\", index_col=\"sample\")\n",
    "proteins = pd.read_csv(\"challenge_data/train_pro.tsv\", sep=\"\\t\")\n",
    "# Transpose proteins matrix\n",
    "proteins = proteins.T\n",
    "misClassified = pd.read_csv(\"challenge_data/sum_tab_1.csv\", sep=\",\")\n",
    "# Replace missing values with median\n",
    "proteins = proteins.fillna(proteins.median())\n",
    "# Drop remaining columns with missing values\n",
    "proteins = proteins.dropna(axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select only rows which were correctly classified (matches) for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = list(misClassified.query('mismatch==0').loc[:,\"sample\"])\n",
    "x = proteins.loc[matches]\n",
    "y = labels.loc[matches]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Classifications\n",
    "First exploration of how different classifiers perform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for combining the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineLabels(a, b):\n",
    "    combined =  [None] * len(a)\n",
    "    for i in range(len(a)):\n",
    "        if (a[i] == 0 and b[i] == 0):\n",
    "            combined[i] = 0\n",
    "        if (a[i] == 0 and b[i] == 1):\n",
    "            combined[i] = 1\n",
    "        if (a[i] == 1 and b[i] == 0):\n",
    "            combined[i] = 2\n",
    "        if (a[i] == 1 and b[i] == 1):\n",
    "            combined[i] = 3\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test a classifier on msi, gender and combined labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(x, y, clf):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, shuffle=True)\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    # I will have separat models for gende and msi\n",
    "    y_gender_train = lb.fit_transform(y_train.loc[:,\"gender\"]).ravel()\n",
    "    y_gender_test = lb.fit_transform(y_test.loc[:,\"gender\"]).ravel()\n",
    "    y_msi_train = lb.fit_transform(y_train.loc[:,\"msi\"]).ravel()\n",
    "    y_msi_test = lb.fit_transform(y_test.loc[:,\"msi\"]).ravel()\n",
    "\n",
    "    y_combined_train = combineLabels(y_gender_train, y_msi_train)\n",
    "    y_combined_test = combineLabels(y_gender_test, y_msi_test)\n",
    "\n",
    "    clf.fit(x_train, y_gender_train)\n",
    "\n",
    "    y_gender_predict = clf.predict(x_train)\n",
    "    print(\"Gender train accuracy:\", accuracy_score(y_gender_train, y_gender_predict))\n",
    "\n",
    "    y_gender_predict = clf.predict(x_test)\n",
    "    print(\"Gender test accuracy:\", accuracy_score(y_gender_test, y_gender_predict))\n",
    "\n",
    "    clf.fit(x_train, y_msi_train)\n",
    "\n",
    "    y_msi_predict = clf.predict(x_train)\n",
    "    print(\"Msi train accuracy:\", accuracy_score(y_msi_train, y_msi_predict))\n",
    "\n",
    "    y_msi_predict = clf.predict(x_test)\n",
    "    print(\"Msi test accuracy:\", accuracy_score(y_msi_test, y_msi_predict))\n",
    "    \n",
    "    clf.fit(x_train, y_combined_train)\n",
    "    \n",
    "    y_combined_predict = clf.predict(x_train)\n",
    "    print(\"Combined train accuracy:\", accuracy_score(y_combined_train, y_combined_predict))\n",
    "    # print(\"Msi train F1:\", f1_score(y_msi_train, y_msi_predict))\n",
    "\n",
    "    y_combined_predict = clf.predict(x_test)\n",
    "    print(\"Combined test accuracy:\", accuracy_score(y_combined_test, y_combined_predict))\n",
    "    # print(\"Msi train F1:\", f1_score(y_msi_test, y_msi_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM\n",
    "\n",
    "* It seems that a high penalty needs to be set for SVM, otherwise it assigns the more frequent label (female and low msi) to everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Gender train accuracy:', 1.0)\n",
      "('Gender test accuracy:', 0.7142857142857143)\n",
      "('Msi train accuracy:', 1.0)\n",
      "('Msi test accuracy:', 0.8571428571428571)\n",
      "('Combined train accuracy:', 1.0)\n",
      "('Combined test accuracy:', 0.5238095238095238)\n"
     ]
    }
   ],
   "source": [
    "classify(x, y, SVC(C=100, kernel=\"rbf\", gamma=\"scale\", probability=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Gender train accuracy:', 1.0)\n",
      "('Gender test accuracy:', 0.6666666666666666)\n",
      "('Msi train accuracy:', 1.0)\n",
      "('Msi test accuracy:', 0.8095238095238095)\n",
      "('Combined train accuracy:', 0.9787234042553191)\n",
      "('Combined test accuracy:', 0.47619047619047616)\n"
     ]
    }
   ],
   "source": [
    "classify(x, y, RandomForestClassifier(n_estimators = 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Gender train accuracy:', 0.723404255319149)\n",
      "('Gender test accuracy:', 0.6666666666666666)\n",
      "('Msi train accuracy:', 0.9787234042553191)\n",
      "('Msi test accuracy:', 0.9047619047619048)\n",
      "('Combined train accuracy:', 0.723404255319149)\n",
      "('Combined test accuracy:', 0.6666666666666666)\n"
     ]
    }
   ],
   "source": [
    "classify(x, y, KNeighborsClassifier(n_neighbors=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it's time to figure out the best parameters for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender = y.loc[:,\"gender\"]\n",
    "msi = y.loc[:,\"msi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestParams(x, y, clf, grid):\n",
    "    grid_search = GridSearchCV(clf, param_grid=grid, cv=10, iid=False)\n",
    "    grid_search.fit(x, y)\n",
    "    print(\"Tuned params:\", grid_search.best_params_)\n",
    "    print(\"Tuned best acc:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for gender\n",
      "('Tuned params:', {'n_estimators': 10, 'max_depth': 104})\n",
      "('Tuned best acc:', 0.7327380952380953)\n",
      "Best params for msi\n",
      "('Tuned params:', {'n_estimators': 10, 'max_depth': 39})\n",
      "('Tuned best acc:', 0.9125)\n"
     ]
    }
   ],
   "source": [
    "grid = {\n",
    "    \"n_estimators\": range(5, 35, 5),\n",
    "    \"max_depth\": range(4, 120, 5)\n",
    "}\n",
    "print(\"Best params for gender\")\n",
    "bestParams(x, gender, RandomForestClassifier(), grid)\n",
    "print(\"Best params for msi\")\n",
    "bestParams(x, msi, RandomForestClassifier(), grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for gender\n",
      "('Tuned params:', {'kernel': 'rbf', 'C': 10, 'gamma': 'auto'})\n",
      "('Tuned best acc:', 0.6708333333333334)\n",
      "Best params for msi\n",
      "('Tuned params:', {'kernel': 'linear', 'C': 0.01, 'gamma': 'auto'})\n",
      "('Tuned best acc:', 0.9)\n"
     ]
    }
   ],
   "source": [
    "grid = {\n",
    "    \"C\": [pow(10,i) for i in range(-2,4)],\n",
    "    \"kernel\": [\"linear\", \"rbf\"],\n",
    "    \"gamma\": [\"auto\", \"scale\"]\n",
    "}\n",
    "print(\"Best params for gender\")\n",
    "bestParams(x, gender, SVC(), grid)\n",
    "print(\"Best params for msi\")\n",
    "bestParams(x, msi, SVC(), grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for gender\n",
      "('Tuned params:', {'n_neighbors': 5})\n",
      "('Tuned best acc:', 0.7345238095238096)\n",
      "Best params for msi\n",
      "('Tuned params:', {'n_neighbors': 9})\n",
      "('Tuned best acc:', 0.9041666666666668)\n"
     ]
    }
   ],
   "source": [
    "grid = {\n",
    "    \"n_neighbors\": range(1,20)\n",
    "}\n",
    "print(\"Best params for gender\")\n",
    "bestParams(x, gender, KNeighborsClassifier(), grid)\n",
    "print(\"Best params for msi\")\n",
    "bestParams(x, msi, KNeighborsClassifier(), grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Combine msi and gender?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Msi seems to be better indicator than gender. How do we take this into account?\n",
    "\n",
    "* MSI does not match --> Mismatch label, no matter what gender says\n",
    "* MSI matching, gender mismatch - what do we do?\n",
    "* I propose to calculate a confidence score and use it in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Confidence Score\n",
    "* Instead of reporting just label, show model's confidence score. This can help us decide in case of matching msi and gender misclassification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Gender test accuracy:', 0.6190476190476191)\n",
      "(array([0.68232265, 0.31767735]), 1)\n",
      "(array([0.69272413, 0.30727587]), 0)\n",
      "(array([0.68428927, 0.31571073]), 1)\n",
      "(array([0.68667506, 0.31332494]), 0)\n",
      "(array([0.6249667, 0.3750333]), 1)\n",
      "(array([0.45015556, 0.54984444]), 1)\n",
      "(array([0.82886351, 0.17113649]), 1)\n",
      "(array([0.66656119, 0.33343881]), 0)\n",
      "(array([0.66511439, 0.33488561]), 1)\n",
      "(array([0.74174193, 0.25825807]), 0)\n",
      "(array([0.78911414, 0.21088586]), 1)\n",
      "(array([0.68384196, 0.31615804]), 0)\n",
      "(array([0.81968649, 0.18031351]), 0)\n",
      "(array([0.65743684, 0.34256316]), 0)\n",
      "(array([0.74588987, 0.25411013]), 0)\n",
      "(array([0.64746958, 0.35253042]), 0)\n",
      "(array([0.86540917, 0.13459083]), 1)\n",
      "(array([0.66728588, 0.33271412]), 1)\n",
      "(array([0.76230683, 0.23769317]), 0)\n",
      "(array([0.55475304, 0.44524696]), 1)\n",
      "(array([0.75708745, 0.24291255]), 0)\n",
      "()\n",
      "('Msi test accuracy:', 1.0)\n",
      "(array([0.15381273, 0.84618727]), 1)\n",
      "(array([0.03480029, 0.96519971]), 1)\n",
      "(array([0.1559887, 0.8440113]), 1)\n",
      "(array([0.08524463, 0.91475537]), 1)\n",
      "(array([0.66457062, 0.33542938]), 0)\n",
      "(array([0.08838087, 0.91161913]), 1)\n",
      "(array([0.02381407, 0.97618593]), 1)\n",
      "(array([0.07354278, 0.92645722]), 1)\n",
      "(array([0.08643869, 0.91356131]), 1)\n",
      "(array([0.84184809, 0.15815191]), 0)\n",
      "(array([0.1406746, 0.8593254]), 1)\n",
      "(array([0.24675432, 0.75324568]), 1)\n",
      "(array([0.15267025, 0.84732975]), 1)\n",
      "(array([0.03410449, 0.96589551]), 1)\n",
      "(array([0.11117382, 0.88882618]), 1)\n",
      "(array([0.52740288, 0.47259712]), 0)\n",
      "(array([0.14477598, 0.85522402]), 1)\n",
      "(array([0.85975401, 0.14024599]), 0)\n",
      "(array([0.08284083, 0.91715917]), 1)\n",
      "(array([0.13645816, 0.86354184]), 1)\n",
      "(array([0.09175199, 0.90824801]), 1)\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(C=100, kernel=\"rbf\", gamma=\"scale\", probability=True)\n",
    "#clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, shuffle=True, random_state=100)\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "y_gender_train = lb.fit_transform(y_train.loc[:,\"gender\"]).ravel()\n",
    "y_gender_test = lb.fit_transform(y_test.loc[:,\"gender\"]).ravel()\n",
    "y_msi_train = lb.fit_transform(y_train.loc[:,\"msi\"]).ravel()\n",
    "y_msi_test = lb.fit_transform(y_test.loc[:,\"msi\"]).ravel()\n",
    "\n",
    "clf.fit(x_train, y_gender_train)\n",
    "y_gender_predict = clf.predict(x_test)\n",
    "print(\"Gender test accuracy:\", accuracy_score(y_gender_test, y_gender_predict))\n",
    "probs = clf.predict_proba(x_test)\n",
    "for i in range(len(probs)):\n",
    "    print(probs[i] , y_gender_test[i])\n",
    "print()\n",
    "\n",
    "clf.fit(x_train, y_msi_train)\n",
    "y_msi_predict = clf.predict(x_test)\n",
    "print(\"Msi test accuracy:\", accuracy_score(y_msi_test, y_msi_predict))\n",
    "probs = clf.predict_proba(x_test)\n",
    "for i in range(len(probs)):\n",
    "    print(probs[i], y_msi_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, it does not look like the confidence is helpful when predicting gender"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
